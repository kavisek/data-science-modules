{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining applications for data science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/developers/<BR>\n",
    "http://scikit-learn.org/stable/faq.html<BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506L, 13L) (506L,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "X, y = boston.data,boston.target\n",
    "print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, normalize=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "hypothesis = LinearRegression(normalize=True)\n",
    "hypothesis.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -1.07170557e-01   4.63952195e-02   2.08602395e-02   2.68856140e+00\n",
      "  -1.77957587e+01   3.80475246e+00   7.51061703e-04  -1.47575880e+00\n",
      "   3.05655038e-01  -1.23293463e-02  -9.53463555e-01   9.39251272e-03\n",
      "  -5.25466633e-01]\n"
     ]
    }
   ],
   "source": [
    "print hypothesis.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.8972783977\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "new_observation = np.array([1,0,1,0,0.5,7,59,6,3,200,20,350,4],dtype=float)\n",
    "print hypothesis.predict(new_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74060774286494291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01116872  0.          0.01979472  0.          0.23662551  0.65893849\n",
      "  0.57775489  0.44288845  0.08695652  0.02480916  0.78723404  0.88173887\n",
      "  0.06263797]\n"
     ]
    }
   ],
   "source": [
    "#help(LinearRegression)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit(X)\n",
    "print scaler.transform(new_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing the Hashing Trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using hash functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-539294296\n",
      "296\n"
     ]
    }
   ],
   "source": [
    "print hash('Python')\n",
    "print abs(hash('Python')) % 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating the hashing trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "string_1 = 'Python for data science'\n",
    "string_2 = 'Python for machine learning'\n",
    "\n",
    "def hashing_trick(input_string, vector_size=20):\n",
    "    feature_vector = [0] * vector_size\n",
    "    for word in input_string.split(' '):\n",
    "        index = abs(hash(word)) % vector_size\n",
    "        feature_vector[index] = 1\n",
    "    return feature_vector\n",
    "\n",
    "print hashing_trick(input_string='Python for data science', vector_size=20)\n",
    "print hashing_trick(input_string='Python for machine learning', vector_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 16)\t1\n",
      "  (0, 18)\t1\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "print csc_matrix([1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x20 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 8 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "sklearn_hashing_trick = HashingVectorizer(n_features=20, binary=True, norm=None)\n",
    "hashed_text = sklearn_hashing_trick.transform(['Python for data science','Python for machine learning'])\n",
    "hashed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "one_hot_enconder = CountVectorizer()\n",
    "one_hot_enconded = one_hot_enconder.fit_transform(['Python for data science','Python for machine learning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'machine': 3, u'learning': 2, u'for': 1, u'python': 4, u'science': 5, u'data': 0}\n"
     ]
    }
   ],
   "source": [
    "print one_hot_enconder.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x20 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_hashing_trick.transform(['New text has arrived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x4 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_enconder.fit_transform(['New text has arrived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 96.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit l = [k for k in range(10**6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 loops, best of 5: 95.7 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 20 -r 5 l = [k for k in range(10**6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 163 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "l = list()\n",
    "for k in range(10**6):\n",
    "    l.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer, CountVectorizer\n",
    "sklearn_hashing_trick = HashingVectorizer(n_features=20, binary=True, norm=None) \n",
    "one_hot_enconder = CountVectorizer()\n",
    "texts = ['Python for data science','Python for machine learning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.25 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit one_hot_enconded = one_hot_enconder.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 154 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit  hashing = sklearn_hashing_trick.transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000155533324034\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "cumulative_time = timeit.timeit(\"hashing = sklearn_hashing_trick.transform(texts)\", \n",
    "                                 \"from __main__ import sklearn_hashing_trick, texts\", \n",
    "                                 number=10000)\n",
    "print cumulative_time / 10000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation procedures from the command line:\n",
    "# pip install psutil\n",
    "# pip install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization from IPython (to be repeat at every IPython start)\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 81.66 MiB, increment: 0.11 MiB\n"
     ]
    }
   ],
   "source": [
    "hashing = sklearn_hashing_trick.transform(texts)\n",
    "%memit dense_hashing = hashing.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting example_code.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile example_code.py\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, CountVectorizer\n",
    "def comparison_test():\n",
    "    sklearn_hashing_trick = HashingVectorizer(n_features=20, binary=True, norm=None) \n",
    "    one_hot_enconder = CountVectorizer()\n",
    "    texts = ['Python for data science','Python for machine learning']\n",
    "    one_hot_enconded = one_hot_enconder.fit_transform(texts)\n",
    "    hashing = sklearn_hashing_trick.transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('',)\n"
     ]
    }
   ],
   "source": [
    "from example_code import comparison_test\n",
    "%mprun -f comparison_test comparison_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrating multiprocessing techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "X, y = digits.data,digits.target\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit single_core_learning = cross_val_score(SVC(), X, y, cv=20, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit multi_core_learning = cross_val_score(SVC(), X, y, cv=20, n_jobs=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
